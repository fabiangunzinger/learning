{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "Based on chaters in Applied Predictive Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General points\n",
    "\n",
    "- Having many uninformative features in your model might lower performance as it makes is more likely that the model overfits (e.g. including country names when predicting life satisfaction and using OECD sample finds that \"w\" in country name predicts high life satisfaction because of Norway, Switzerland, New Zealand, and Sweden. But this doesn't generalize to Rwanda and Zimbabwe). Hence, the more uninformative features, the bigger the chance that the model will find a pattern by chance in one of them in your training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process in practice\n",
    "\n",
    "1. Brainstorm features\n",
    "2. Decide what features to create\n",
    "3. Create the features\n",
    "4. Test impact on model performance\n",
    "5. Interacting on features is useful\n",
    "6. Iterate (go to 3 or 1)\n",
    "\n",
    "Stuff to try:\n",
    "- Ratios\n",
    "- Counts\n",
    "- Cutoff points\n",
    "- Iterate on features (change cutoff and see whether it makes a difference) \n",
    "- Rate of Change in Values\n",
    "- Range of Values\n",
    "- Density within Intervals of Time\n",
    "- Proportion of Instances of Commonly Occurring Values\n",
    "- Time Between Occurrences of Commonly Occurring Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "- Data transformations for individual predictors\n",
    "\n",
    "- Data transformations for multiple predictors\n",
    "\n",
    "- Dealing with missing values\n",
    "\n",
    "- Removing predictors\n",
    "\n",
    "- Adding predictors\n",
    "\n",
    "- Binning predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring predictor importance\n",
    "\n",
    "- Numeric outcomes\n",
    "\n",
    "- Categorical outcomes\n",
    "\n",
    "- Other approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "- Consequences of using non-informative predictors\n",
    "\n",
    "- Approaches for reducing the number of predictors\n",
    "\n",
    "- Wrapper methods\n",
    "\n",
    "- Filter methods\n",
    "\n",
    "- Selection bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factors that can affect model performance\n",
    "\n",
    "- Type III errors\n",
    "\n",
    "- Measurement errors in the outcome\n",
    "\n",
    "- Measurement errors in the predictors\n",
    "\n",
    "- Distretising continuous outcomes\n",
    "\n",
    "- When should you trust your model's prediction?\n",
    "\n",
    "- The impact of a large sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- [video](https://www.youtube.com/watch?time_continue=109&v=drUToKxEAUA&feature=emb_logo)\n",
    "- mlmastery [article](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habits",
   "language": "python",
   "name": "habits"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
